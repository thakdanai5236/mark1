# Environment Configuration 

# API Settings
HOST=0.0.0.0
PORT=8000
DEBUG=false

# LLM Provider Settings
# Use 'ollama' for local models (recommended) or 'openai' for OpenAI API
LLM_PROVIDER=ollama
LLM_TEMPERATURE=0.7

# Ollama Configuration (for local LLM)
# Make sure Ollama is running: ollama serve
# Available models: llama2, mistral, neural-chat, orca-mini, etc
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama2

# OpenAI Configuration (if using LLM_PROVIDER=openai)
# OPENAI_API_KEY=your_openai_api_key_here
# LLM_MODEL=gpt-4

# Vector Store Settings
VECTOR_STORE_PATH=data/vector_store
EMBEDDING_MODEL=text-embedding-ada-002

# Data Paths
RAW_DATA_PATH=data/raw
PROCESSED_DATA_PATH=data/processed
